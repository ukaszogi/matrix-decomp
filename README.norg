* Matrix decomposition

  Worked on it before attending any university, I just asked some prof at a local uni if he'd like to give me some challanges.

  Didn't ever manage to get SVD, but at least now i know (thanks to lin algebra 2 course) that it isn't so straight forward.

** 2025-05-08 19:35

   Class implementation. 

   - (-) Basic Matrix class
   -- (x) Shape
   -- (x) Indexing
   -- ( ) Slices
   -- (x) Addition
   -- (x) Multiplication
   -- (x) Transposition
   -- (x) Create zeroed matrix with desired shape
          `Null().collapse(n, m)`
   - ( ) Collapsible
         Collapsible is a class designed to /collapse/ to the desired shape, when it's modifing another matrix.
         General problem with it is the order of operations:
   ~~ Check for shape errors
   ~~ Collapse
   ~~ Do any operations
   ~~ Compute if necessery

   About the wording. *collapsed* sould already gibe collapsed result. *collapse* should indicate, that we got new insight about the dimension 

   -- (?) Detecting matmul in abstract class
   -- (x) Identity
   --- (x) Indexing
   --- (x) Matrix-Multiplication
   --- (x) Matrix-Addition
   -- (x) Null
   --- (x) Indexing
   --- (x) Matrix-Multiplication
   --- (x) Matrix-Addition
   -- ( ) Null-Identity-Addition
   -- ( ) Null-Identity-Multiplication
   -- ( ) Elementary operations
   --- ( ) Row-scaling /D ,i, (m)/
   ---- (x) Add, matmul opts.
   ---- ( ) Print
   ---- ( ) rmatmul
   --- ( ) Row-addition /L ,|i\,j|, (m)/
   ---- (x) Add, matmul opts.
   ---- ( ) Print
   ---- ( ) rmatmul
   --- ( ) Row-switching /T ,i\,j,/
   ---- (x) Add, matmul opts.
   ---- ( ) Print
   ---- ( ) rmatmul

   Core questions:

*** Hierarchy of optimalisation

    Only at the last moment should i go to normal matmul. If i know at least one matrix is a special one, and i can write some code, that instead of O(n^3) O(n) does, i should do it. Of course, less code means less bugs, but bugs are at least visible.

    I dont have to calculate the matrix at initialisation. Technically, if i have elementary and a matrix, i can do (sometimes even O(1)) on the matrix and not even collapse the elementary. If the calculation is in-place, i'll end up with just another /normal/ matrix, which has to be calculated.

*** What about square matrices?

    Right now many considered operation only make sanse on squared matrices: some decompositions and determinant f.e.

*** How abstract should i get?

    In pursuit of optimalisation I think about `MatrixAndInverse` class, where the inverse would be sequentialy updated, so:
    @code python
    class MatrixAndInverse(Matrix):
      def __init__(self, a):
    self.__pri = super().__init__(a)
    self.__inv = self.__pri.inverse()

    def __mul__(self, other):
      self.__pri = self.__pri * other.__pri
    self.__inv = other.__inv * self.__inv
    @end

    Really good for LR, elementary matricies would be of that class. But is it usefull?
    I could just keep track of the inverse with another object, just for the LR
